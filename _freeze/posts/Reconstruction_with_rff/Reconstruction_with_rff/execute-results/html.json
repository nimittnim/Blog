{
  "hash": "3ed61c1a041cd2686931f9fdfb5e8f2b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Improving Linear Regression using Random Fourier Feautures\"\nauthor: Nimitt\ndate: 2023-03-15\ncategories: [Machine Learning]\ndescription: \"Convolutional Neural Network\"\njupyter: python3\nexecute:\n  eval: false  \n---\n\n::: {#94b25e4d .cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport torch.optim as optim\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nfrom einops import rearrange\nfrom sklearn import preprocessing\n```\n:::\n\n\n::: {#7e7c9479 .cell execution_count=2}\n``` {.python .cell-code}\ndef mask_image_patch(img,x,y,z,patch_size):\n    img_copy = img.clone()\n    for i in range(patch_size):\n        for j in range(patch_size):\n                for k in range(z):\n                    img_copy[x+i][y+j][k] = torch.nan\n    return img_copy\n\ndef mask_image_random(img,patch_size):\n    img_copy = img.clone()\n    n = len(img)\n    m = len(img[0])\n    random_i = np.random.choice(n*m,patch_size*patch_size,replace=False)\n    for i in random_i:\n        for j in range(3):\n            img_copy[i//n][i%m] = torch.nan\n    return img_copy\n\ndef create_mask(t,x,y,patch_size):\n    mask = torch.full(t.shape,True)\n    z = t.shape[2]\n    for i in range(patch_size):\n        for j in range(patch_size):\n                for k in range(z):\n                    mask[x+i][y+j][k] = False\n    return mask\n\ndef create_coordinate_map(img):\n    height, width, num_channels = img.shape\n    X = torch.empty((img.shape[0],img.shape[1],2))\n    \n    for i in range(height):\n        for j in range(width):\n            X[i][j][0] = i\n            X[i][j][1] = j\n    return X.reshape(-1,2)\n\ndef stack_itself(t, n):\n    stacked_t = t.unsqueeze(1).expand(-1, n, -1)\n    return stacked_t.squeeze()\n\ndef scale(img):\n    img_flatted = img.reshape(-1,1)\n    scaler_X = preprocessing.MinMaxScaler().fit(img_flatted)\n    img_scaled = scaler_X.transform(img_flatted).reshape(img.shape)\n    img_scaled = torch.tensor(img_scaled)\n    img_scaled = img_scaled.float()\n    return img_scaled\n\ndef fill_patch(original_img,reconstructed_img_patch,x,y,patch_size):\n    reconstructed_img = original_img.clone()\n    for i in range(patch_size):\n        for j in range(patch_size):\n                for k in range(3):\n                    reconstructed_img[x+i][y+j][k] = reconstructed_img_patch[i][j][k]\n    return reconstructed_img\n```\n:::\n\n\n::: {#b1cdb639 .cell execution_count=3}\n``` {.python .cell-code}\nimg = torchvision.io.read_image('dog.jpg')\nimg_scaled = scale(img)\ncropped_img = torchvision.transforms.functional.crop(img_scaled,600,800,300,300)\ncropped_img = rearrange(cropped_img,'c h w -> h w c')\ncropped_img = torch.tensor(cropped_img,dtype = torch.float32)\noriginal_img = cropped_img.clone()\n```\n:::\n\n\n::: {#99e2ba52 .cell execution_count=4}\n``` {.python .cell-code}\n# LR + RFF\ndef plot_reconstructed_and_original_image(original_img, masked_img, reconstructed_img, title=\"\"):\n    \"\"\"\n    net: torch.nn.Module\n    X: torch.Tensor of shape (num_samples, 2)\n    Y: torch.Tensor of shape (num_samples, 3)\n    \"\"\"\n    fig = plt.figure(figsize=(6, 4))\n    gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 1])\n\n    ax0 = plt.subplot(gs[0])\n    ax1 = plt.subplot(gs[1])\n    ax2 = plt.subplot(gs[2])\n\n    ax0.imshow(reconstructed_img)\n    ax0.set_title(\"Reconstructed Image\")\n    \n    ax1.imshow(original_img.cpu())\n    ax1.set_title(\"Original Image\")\n\n    ax2.imshow(masked_img.cpu())\n    ax2.set_title(\"Masked Image\")\n\n    \n    for a in [ax0, ax1, ax2]:\n        a.axis(\"off\")\n    plt.show()\n\ndef create_rff_features(X, num_features, sigma):\n    from sklearn.kernel_approximation import RBFSampler\n    rff = RBFSampler(n_components=num_features, gamma=1/(2 * sigma**2))\n    X = X.cpu().numpy()\n    X = rff.fit_transform(X)\n    return torch.tensor(X, dtype=torch.float32)\n\ndef train(net, lr, X, Y, max_epochs=2000):\n    \"\"\"\n    net: torch.nn.Module\n    lr: float\n    X: torch.Tensor of shape (known_pixels, 2) // (x,y)\n    Y: torch.Tensor of shape (known_pixels, 3) // (r,g,b)\n    \"\"\"\n\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    outputs = net(X)\n    loss = criterion(outputs, Y)\n    \n    prev_loss = float('inf')  \n    epsilon = 1e-5\n    prev_loss = float('inf')\n    max_epochs = 10000\n    \n    for i in range(max_epochs):\n        optimizer.zero_grad()\n        outputs = net(X)\n        loss = criterion(outputs, Y)\n        loss.backward()\n        optimizer.step()\n\n        if abs(prev_loss - loss.item()) < epsilon:\n            break\n        prev_loss = loss.item()\n\n\n\nclass LinearModel(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(LinearModel, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        \n    def forward(self, x):\n        return self.linear(x)\n    \n\ndef image_reconstrunction_linear_rff(original_img,masked_img):\n    \n    y = original_img.clone().reshape(-1,3)\n    X = create_coordinate_map(original_img)\n    mask = ~torch.isnan(masked_img).reshape(-1,3)\n    X_train = X[mask[:,0:2]].reshape(-1,2)\n    y_train = y[mask].reshape(-1,3)\n\n    # Without RFF\n    # net = LinearModel(2,3)\n    # train(net,0.01,X_train,y_train,1000)\n    # plot_reconstructed_and_original_image(original_img, net, X, title=\"Reconstructed Image\")\n\n    # With RFF\n    features = 10000\n    X_rff = create_rff_features(X, features, 0.008)\n    mask_rff = stack_itself(mask[:,0].unsqueeze(1),features)\n    X_rff_train = X_rff[mask_rff].reshape(-1,features)\n    y_rff_train = y[mask].reshape(-1,3)\n\n    \n    netrff = LinearModel(X_rff_train.shape[1], 3)\n    train(netrff, 0.005, X_rff_train, y_rff_train, 1000)\n    height, width, num_channels = original_img.shape\n    netrff.eval()\n    with torch.no_grad():\n        reconstructed_img = netrff(X_rff).reshape(height,width,num_channels)\n    return reconstructed_img\n```\n:::\n\n\n::: {#8e02273b .cell execution_count=5}\n``` {.python .cell-code}\ndef mse(original_img,reconstructed_img):\n    sum = torch.tensor(0)\n    for i in range(3):\n        sum = sum + (nn.functional.mse_loss(original_img[:,:,i],reconstructed_img[:,:,i]))\n    return sum/3\n\ndef psnr(original_img,reconstructed_img):\n    psnr = torch.tensor(0)\n    for i in range(3):\n        maxi = torch.max(original_img[:,:,i])\n        mse = nn.functional.mse_loss(original_img[:,:,i],reconstructed_img[:,:,i])\n        psnr = psnr + (20*torch.log10(maxi/mse))\n    return psnr/3\n```\n:::\n\n\n::: {#1ed19f48 .cell execution_count=6}\n``` {.python .cell-code}\n# 1a RFF\npatch_size = 30\n# x_y_s = [[10,10],[90,150],[140,60]]\nx_y_s = [[90,150]]\nreconstructed_images_2 = []\n\nfor i in range(len(x_y_s)):\n    print(\"Linear Regression + RFF for 30*30 rectangular patch\")\n    masked_img = mask_image_patch(original_img,x_y_s[i][0],x_y_s[i][1],3,patch_size)\n    reconstructed_img = image_reconstrunction_linear_rff(original_img,masked_img)\n    reconstructed_images_2.append(reconstructed_img)\n    plot_reconstructed_and_original_image(original_img, masked_img, reconstructed_img, title=\"Reconstructed Image with RFF Features\")\n    print(\"MSE for reconstruction : \",mse(original_img, reconstructed_img))\n    print(\"PSNR for reconstruction : \",psnr(original_img, reconstructed_img))\n```\n:::\n\n\n::: {#d2a617f1 .cell execution_count=7}\n``` {.python .cell-code}\n# 1b RFF\npatch_size = 30\ntitles = [\"Random Missing pixels RFF\"]\nreconstructed_images_4 = []\n\nprint(titles[0])\nmasked_img = mask_image_random(original_img, patch_size)\nreconstructed_img = image_reconstrunction_linear_rff(original_img, masked_img)\nreconstructed_images_4.append(reconstructed_img)\nfig,axs = plt.subplots(1,2)\naxs[0].imshow(masked_img)\naxs[1].imshow(reconstructed_img)\nplt.show()\nprint(\"MSE for reconstruction : \",mse(original_img, reconstructed_img))\nprint(\"PSNR for reconstruction : \",psnr(original_img, reconstructed_img))\n```\n:::\n\n\n",
    "supporting": [
      "Reconstruction_with_rff_files"
    ],
    "filters": [],
    "includes": {}
  }
}